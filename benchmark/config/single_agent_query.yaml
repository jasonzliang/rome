# HumanEval Benchmark Configuration - Basic

OpenAIHandler:
  cost_limit: 500.0

Agent:
  name: "PythonCodeExpert"
  role: "You are an expert Python developer tasked with implementing functions to pass all given test cases. Focus on writing clean, efficient, and well-tested code that handles edge cases properly."
  agent_api: false

  fsm_type: knowledge_base
  action_select_strat: original
  patience: 5

  use_ground_truth: False
  save_insights: False
  query_insights: True


ChromaClientManager:
  # collection_name: 9_18_knowledge_base_multi
  collection_name: 9_24_multi_insight

Logger:
  include_caller_info: "rome"
